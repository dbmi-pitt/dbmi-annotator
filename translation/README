--------------------------------------------------------------------
Create database mpevidence: running DDL
--------------------------------------------------------------------

(1) Install postgres DB if it's development mode. Create database "mpevidence"

(2) Execute RDB schema creation script in Postgres DB:
<path to>/dbmi-annotator/db-schema/mp_evidence_schema.sql

--------------------------------------------------------------------
Preparetion
--------------------------------------------------------------------

Install python postgres connector 
pip install psycopg2

-----------------------------------------------------------------------
translate MP annotations from elasticsearch and load into postgres DB
-----------------------------------------------------------------------

$ cd mp-evidence-base-ETL

execute ETL program loadAnnotatorAnnsToRDB.py 

$ python loadAnnotatorAnnsToRDB.py <elastic host> <elastic port> <pg host> <pg port> <pg username> <pg password> <OPTIONS (1: clean all tables, 2 drop and recreate all tables, 0: keep existing data)>

Development mode:
ex. $ python loadAnnotatorAnnsToRDB.py localhost 9200 localhost 5432 dbmiannotator dbmi2016 1

Docker container:
$ python loadAnnotatorAnnsToRDB.py elasticsearch 9200 postgres 5432 dbmiannotator dbmi2016 0

--------------------------------------------------------------------
testing ETL
--------------------------------------------------------------------

Description: testing the ETL program in following steps
  
(1) Load sample annotation as test case for "DDI Clinicaltrial", "Phenotype clinical study", "Case Report", "Statement" to Elasticsearch 
(2) Query annotations on Elasticsearch, translate to Micropublication model and load into Postgres DB
(3) Query Postgres DB, compare all fields with sample annotation
(4) Print out testing report to shell

$ python validate.py

--------------------------------------------------------------------
query and export annotations from elasticsearch to csv
--------------------------------------------------------------------

Description: Query Elasticsearch for MP annotations and dump to csv file. Enable customize query condition to specify the exporting data set 

(1) specify query condition in run() for script: exportAnnsInElasticoToCsv.py

for example:

        qryCondition = {"query": {"bool": 
              {"must": [
                      {"term": {"rawurl": "http://localhost/DDI-labels/829a4f51-c882-4b64-81f3-abfb03a52ebe.html"}},
                      {"term": {"annotationType": "MP"}}
              ]
         }}}

(2) python exportAnnsInElasticoToCsv.py

(3) results will be saved at: data/exported-mp-annotations.csv

----------------------------------------------------------------------------------
Load annotations from postgres DB mpevidence to Elasticsearch store (Not ready)
----------------------------------------------------------------------------------

(1) Query Micropublication annotations from Relational database (Postgres) mpevidence 
(2) Translate annotation to JSON format and load into Elastico document store

python load-rdb-annotations.py <pg hostname> <pg username> <pg password> <es hostname> <annotation author>

Development mode:
ex. 
$ python load-rdb-annotations.py localhost dbmiannotator dbmi2016 localhost test@gmail.com

Docker container:
$ python load-rdb-annotations.py postgres dbmiannotator dbmi2016 elasticsearch test@gmail.com

-----------------------------------------------------------------------
Load domeo annotations from csv and load into postgres DB (deprecated)
-----------------------------------------------------------------------

(1) Ensure csv annotation set from extracted from Domeo is available at:
 
dbmi-annotator/translation/csv-data-loader/data/pkddi-<username>-latest-<date>.csv

(2) Configure data for loadDomeoAnnsToRDB.py

csvfiles = ['data/pkddi-katrina-latest-08152016.csv', 'data/pkddi-amy-latest-08152016.csv']

Note: If csv comes from domeo, replace cl to clearance and t12 to halflife

(3) execute ETL program loadDomeoAnnsToRDB.py 

$ python loadDomeoAnnsToRDB.py <pg hostname> <pg port> <pg username> <pg password> <OPTIONS (1: clean all tables, 2 drop and recreate all tables, 0: keep existing data)>

Development mode:
ex. python loadDomeoAnnsToRDB.py localhost 5432 dbmiannotator dbmi2016 1

Docker container:
$ python loadDomeoAnnsToRDB.py postgres 5432 dbmiannotator dbmi2016 1

1. optional: clean all data in table
2. preprocess csv, generate preprocess-domeo.csv
3. load data into schema mpevidence

--------------------------------------------------------------------
Apply DIDEO ontology 
--------------------------------------------------------------------

(1) Load dideo.owl to OWL2TL to produce term lists in dideo ontology

OWL2TL: https://owl2tl.com/
DIDEO OWL: http://purl.obolibrary.org/obo/dideo.owl

(2) Terms been used in Micropublication annotation

Refers to: omop-concepts-dev/dideo-uris.txt

Script for inserting dideo concepts: omop-concepts-dev/dideo-concepts-insert.sql

--------------------------------------------------------------------
Apply OMOP standard vocabulary Version 5.1 to MP tables 
--------------------------------------------------------------------

(1) create concept tables and load data (refers to OHDSI OMOP CDM V5.1)

http://www.ohdsi.org/web/wiki/doku.php?id=documentation:cdm:single-page

(2) Queries for mapping (MeSH to concept_id and RxNorm to concept_id)

SELECT c.concept_id as omopid, c.concept_name, c.vocabulary_id, cc.concept_class_name, c.concept_code
FROM concept c JOIN concept_class cc on c.concept_class_id = cc.concept_class_id
WHERE c.vocabulary_id = 'MeSH' OR c.vocabulary_id = 'RxNorm'
LIMIT 100;

--------------------------------------------------------------------
D2R server mapping
--------------------------------------------------------------------

D2R server reference: 
http://d2rq.org/getting-started
http://d2rq.org/d2r-server#command-line

Run:
$ cd <path to d2rq directory>
$ ./d2r-server --port 2020 <path to csv-data-loader/d2r-mapping/mpevidence.ttl>

Open browser at "http://localhost:2020"

--------------------------------------------------------------------
D2R server RDF dump (graph mpevidence.rdf)
--------------------------------------------------------------------

Gernerate RDF graph based on d2r mapping configuration 
Reference: http://d2rq.org/dump-rdf

./dump-rdf -f RDF/XML -o mpevidence.rdf --verbose <path to csv-data-loader/d2r-mapping/mpevidence.ttl>

Count instances of claim in RDF graph for validation
grep -r "rdf:Description rdf:about=\"http://dikb.org/mpevidence/mp_claim_annotation" mpevidence.rdf 

--------------------------------------------------------------------
delete specific set of annotations
--------------------------------------------------------------------

(1) delete by specified query condition
curl -XDELETE 'http://localhost:9200/annotator/annotation/_query?q=<field>:<value>'

(2) free store size after deletion 
curl -XPOST 'http://localhost:9200/_optimize?only_expunge_deletes=true'

(3) delete the whole index
curl -XDELETE 'http://localhost:9200/annotator/'
