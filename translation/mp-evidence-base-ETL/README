--------------------------------------------------------------------
Create database mpevidence: running DDL
--------------------------------------------------------------------

(1) Install postgres DB if it's development mode. Create database "mpevidence"

(2) Execute RDB schema creation script in Postgres DB:
<path to>/dbmi-annotator/db-schema/mp_evidence_schema.sql

--------------------------------------------------------------------
Preparetion
--------------------------------------------------------------------

Install python postgres connector 
pip install psycopg2

-----------------------------------------------------------------------
translate MP annotations from elasticsearch and load into postgres DB
-----------------------------------------------------------------------

$ cd mp-evidence-base-ETL

execute ETL program loadAnnotatorAnnsToRDB.py 

$ python loadAnnotatorAnnsToRDB.py <elastic host> <elastic port> <pg host> <pg port> <pg username> <pg password> <OPTIONS (1: clean all tables, 2 drop and recreate all tables, 0: keep existing data)>

Development mode:
ex. $ python loadAnnotatorAnnsToRDB.py localhost 9200 localhost 5432 dbmiannotator dbmi2016 1

Docker container:
$ python loadAnnotatorAnnsToRDB.py elasticsearch 9200 postgres 5432 dbmiannotator dbmi2016 0

-----------------------------------------------------------------------
translate Domeo SPLs annotations from csv and load into postgres DB
-----------------------------------------------------------------------

(1) Ensure csv annotation set from extracted from Domeo is available at:
 
dbmi-annotator/translation/csv-data-loader/data/pkddi-<username>-latest-<date>.csv

(2) Configure data for loadDomeoAnnsToRDB.py

SPLS_CSVS = ['data/pkddi-katrina-latest-08152016.csv', 'data/pkddi-amy-latest-08152016.csv']

Note: If csv comes from domeo, replace cl to clearance and t12 to halflife

(3) execute ETL program loadDomeoAnnsToRDB.py 

$ python loadDomeoAnnsToRDB.py <pg hostname> <pg port> <pg username> <pg password> <OPTIONS (1: clean all tables, 2 drop and recreate all tables, 0: keep existing data)>

Development mode:
ex. python loadDomeoAnnsToRDB.py localhost 5432 dbmiannotator dbmi2016 0

Docker container:
$ python loadDomeoAnnsToRDB.py postgres 5432 dbmiannotator dbmi2016 0

----------------------------------------------------------------------------------
translate and load annotations from postgres DB mpevidence to Elasticsearch store
----------------------------------------------------------------------------------

(1) Query Micropublication annotations from Relational database (Postgres) mpevidence 
(2) Translate annotation to JSON format and load into Elastico document store

python load-rdb-annotations.py <pg hostname> <pg username> <pg password> <es hostname> <annotation author>

Development mode:
ex. 
$ python translateRDB2Elastic.py localhost dbmiannotator dbmi2016 localhost test@gmail.com

Docker container:
$ python translateRDB2Elastic.py postgres dbmiannotator dbmi2016 elasticsearch test@gmail.com

--------------------------------------------------------------------
query and export annotations from elasticsearch to csv
--------------------------------------------------------------------

Description: Query Elasticsearch for MP annotations and dump to csv file. Enable customize query condition to specify the exporting data set 

(1) specify query condition in run() for script: exportAnnsInElasticoToCsv.py

for example:

        qryCondition = {"query": {"bool": 
              {"must": [
                      {"term": {"rawurl": "http://localhost/DDI-labels/829a4f51-c882-4b64-81f3-abfb03a52ebe.html"}},
                      {"term": {"annotationType": "MP"}}
              ]
         }}}

(2) python exportAnnsInElasticoToCsv.py

(3) results will be saved at: data/exported-mp-annotations.csv

--------------------------------------------------------------------
testing ETL program
--------------------------------------------------------------------

Description: testing the ETL program in following steps
  
(1) Load sample annotation as test case for "DDI Clinicaltrial", "Phenotype clinical study", "Case Report", "Statement" to Elasticsearch 
(2) Query annotations on Elasticsearch, translate to Micropublication model and load into Postgres DB
(3) Query Postgres DB, compare all fields with sample annotation
(4) Print out testing report to shell

$ python validate.py
